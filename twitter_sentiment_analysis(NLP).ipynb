{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import json\n",
    "import requests as rq\n",
    "import spacy\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from cleantext import clean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\abhishek\\mypython\\ML\\NLP\\twitter\\training_twitter_x_y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.DataFrame(columns=[\"tweet\",\"sentiment\"])\n",
    "traindf[\"tweet\"]=df[\"text\"]\n",
    "traindf[\"sentiment\"]=df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southwestair scheduled morning 2 days fact yes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southwestair seeing workers time time going lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>united flew ord miami great crew service legs ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>southwestair dultch97 thats horse radish</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united flight ord delayed air force flight sbn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>united load flying sardine knew pilots 2 hours...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jetblue stock response delays frustrating poor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jetblue thatd nice hoping rack miles trip seat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>united frankly worse customer service problems...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>southwestair yeah haha expensive fun destinati...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0  southwestair scheduled morning 2 days fact yes...  negative\n",
       "1  southwestair seeing workers time time going lo...  positive\n",
       "2  united flew ord miami great crew service legs ...  positive\n",
       "3           southwestair dultch97 thats horse radish  negative\n",
       "4  united flight ord delayed air force flight sbn...  negative\n",
       "5  united load flying sardine knew pilots 2 hours...  negative\n",
       "6  jetblue stock response delays frustrating poor...  negative\n",
       "7  jetblue thatd nice hoping rack miles trip seat...  positive\n",
       "8  united frankly worse customer service problems...  negative\n",
       "9  southwestair yeah haha expensive fun destinati...  positive"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>') \n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words\n",
    "punc=string.punctuation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def punc_remover(text):\n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text=text.replace(i,'')\n",
    "    return str(text)\n",
    "\n",
    "def stopwords_remover(text):\n",
    "    text=str(text)\n",
    "    split_text=text.split()\n",
    "    new_text=[]\n",
    "    for i in split_text:\n",
    "        if i not in stopwords:\n",
    "            new_text.append(i)\n",
    "    return \" \".join(new_text)        \n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)            \n",
    "\n",
    "# def spell_correct(text):\n",
    "#     text=str(text)\n",
    "#     textblb=TextBlob(text)\n",
    "#     return textblb.correct().string \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleantext = re.sub(CLEANR, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatizerrr(text):\n",
    "    text=str(text)\n",
    "    split_text=text.split()\n",
    "    new_text=[]\n",
    "    for i in split_text:\n",
    "        tag=pos_tag([i])\n",
    "        lemmatizer.lemmatize(i,pos=get_simple_pos(tag[0][1]))\n",
    "    return \" \".join(split_text) \n",
    "\n",
    "def othercleaning(tweet):\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    return tweet       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[\"tweet\"]=traindf[\"tweet\"].str.lower()\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(punc_remover)\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(stopwords_remover)\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(remove_emojis)\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(cleanhtml)\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(lemmatizerrr)\n",
    "traindf[\"tweet\"]=traindf[\"tweet\"].apply(othercleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(list(traindf[\"tweet\"]),(traindf[\"sentiment\"]) , test_size=0.33, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making vocablary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer(analyzer='word', max_features=3150, max_df = 0.8, ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(X_train)\n",
    "modelx_train=X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=vectorizer.fit_transform(X_test)\n",
    "modelx_test=xt.toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5990618101545254"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C = 2.1, solver='liblinear', multi_class='auto')\n",
    "clf.fit(modelx_train,y_train)\n",
    "clf.score(modelx_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
